{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "084cd65b",
   "metadata": {},
   "source": [
    "First lets install the correct packages for GPT3.  We are already in the conda environment from jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6da380a",
   "metadata": {},
   "source": [
    "First lets install pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56395870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\Popin\\anaconda3\\envs\\jupyter_gpt\n",
      "\n",
      "  added / updated specs:\n",
      "    - cudatoolkit\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2021.10.8  |       h5b45459_0         176 KB  conda-forge\n",
      "    certifi-2021.10.8          |   py37h03978a9_1         145 KB  conda-forge\n",
      "    cudatoolkit-11.6.0         |      hc0ea762_10       965.1 MB  conda-forge\n",
      "    openssl-1.1.1l             |       h8ffe710_0         5.7 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       971.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cudatoolkit        conda-forge/win-64::cudatoolkit-11.6.0-hc0ea762_10\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2022.2.1-h~ --> conda-forge::ca-certificates-2021.10.8-h5b45459_0\n",
      "  certifi            pkgs/main::certifi-2021.10.8-py37haa9~ --> conda-forge::certifi-2021.10.8-py37h03978a9_1\n",
      "  openssl              pkgs/main::openssl-1.1.1m-h2bbff1b_0 --> conda-forge::openssl-1.1.1l-h8ffe710_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   0% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   1% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   1% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   1% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  |            |   1% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | 1          |   1% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | 1          |   1% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | 1          |   2% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | 2          |   2% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | 2          |   2% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | 2          |   3% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | 3          |   3% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | 4          |   4% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | 4          |   5% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | 5          |   6% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | 6          |   6% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | 7          |   7% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | 7          |   8% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | 8          |   8% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | 8          |   9% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | 9          |   9% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #          |  10% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #          |  11% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #1         |  12% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #2         |  13% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #3         |  13% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #4         |  14% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #5         |  15% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #5         |  16% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #6         |  17% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #7         |  18% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #8         |  18% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #9         |  19% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #9         |  20% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ##         |  21% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ##1        |  22% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ##2        |  22% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ##3        |  23% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ##3        |  24% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ##4        |  25% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ##5        |  26% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ##6        |  26% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ##7        |  27% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ##8        |  28% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ##8        |  29% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ##9        |  30% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ###        |  31% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ###1       |  31% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ###2       |  32% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ###3       |  33% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ###4       |  34% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ###4       |  35% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ###5       |  36% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ###6       |  36% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ###6       |  37% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ###7       |  37% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ###8       |  38% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ###8       |  39% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ###9       |  39% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ###9       |  40% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ####       |  40% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ####1      |  41% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ####1      |  42% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ####2      |  42% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ####3      |  43% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ####3      |  44% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ####4      |  45% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ####5      |  45% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ####5      |  46% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ####6      |  46% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ####6      |  47% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ####7      |  48% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ####8      |  48% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ####8      |  49% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ####9      |  50% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #####      |  50% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #####1     |  51% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #####1     |  52% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #####2     |  52% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #####3     |  53% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #####3     |  54% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #####4     |  55% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #####5     |  55% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #####6     |  56% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #####6     |  57% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #####7     |  57% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #####7     |  58% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #####8     |  58% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #####9     |  59% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #####9     |  60% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ######     |  60% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ######     |  61% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ######2    |  62% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ######3    |  63% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ######3    |  64% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ######4    |  65% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ######5    |  65% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ######6    |  66% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ######6    |  67% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ######7    |  68% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ######8    |  69% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ######9    |  69% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #######    |  70% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #######    |  71% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #######1   |  71% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #######2   |  72% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #######2   |  73% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #######3   |  74% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #######4   |  74% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #######4   |  75% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #######5   |  75% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #######5   |  76% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #######6   |  76% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #######6   |  77% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #######7   |  77% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #######7   |  78% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #######8   |  79% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #######9   |  79% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ########   |  80% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ########   |  81% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ########1  |  81% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ########1  |  82% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ########2  |  82% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ########2  |  83% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ########3  |  83% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ########4  |  84% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ########4  |  85% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ########5  |  86% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ########6  |  86% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ########6  |  86% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ########7  |  87% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ########7  |  88% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ########8  |  89% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ########9  |  89% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ########9  |  90% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #########  |  90% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #########  |  91% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #########1 |  92% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #########2 |  92% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #########3 |  93% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #########3 |  94% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #########4 |  94% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #########4 |  95% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #########5 |  95% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #########6 |  96% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #########6 |  97% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #########7 |  97% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #########8 |  98% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #########8 |  99% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | #########9 | 100% \n",
      "cudatoolkit-11.6.0   | 965.1 MB  | ########## | 100% \n",
      "\n",
      "openssl-1.1.1l       | 5.7 MB    |            |   0% \n",
      "openssl-1.1.1l       | 5.7 MB    |            |   0% \n",
      "openssl-1.1.1l       | 5.7 MB    | #7         |  17% \n",
      "openssl-1.1.1l       | 5.7 MB    | ###2       |  33% \n",
      "openssl-1.1.1l       | 5.7 MB    | #########9 | 100% \n",
      "openssl-1.1.1l       | 5.7 MB    | ########## | 100% \n",
      "\n",
      "certifi-2021.10.8    | 145 KB    |            |   0% \n",
      "certifi-2021.10.8    | 145 KB    | #1         |  11% \n",
      "certifi-2021.10.8    | 145 KB    | ########## | 100% \n",
      "\n",
      "ca-certificates-2021 | 176 KB    |            |   0% \n",
      "ca-certificates-2021 | 176 KB    | 9          |   9% \n",
      "ca-certificates-2021 | 176 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... \"By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\" \n",
      "\n",
      "done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge cudatoolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de1de1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\Popin\\anaconda3\\envs\\jupyter_gpt\n",
      "\n",
      "  added / updated specs:\n",
      "    - cudatoolkit\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    cudatoolkit-11.1.1         |       heb2d755_9        1.20 GB  fastchan\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        1.20 GB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2021.10.~ --> pkgs/main::ca-certificates-2022.2.1-haa95532_0\n",
      "  certifi            conda-forge::certifi-2021.10.8-py37h0~ --> pkgs/main::certifi-2021.10.8-py37haa95532_2\n",
      "  openssl            conda-forge::openssl-1.1.1l-h8ffe710_0 --> pkgs/main::openssl-1.1.1m-h2bbff1b_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  cudatoolkit        conda-forge::cudatoolkit-11.6.0-hc0ea~ --> fastchan::cudatoolkit-11.1.1-heb2d755_9\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "cudatoolkit-11.1.1   | 1.20 GB   |            |   0% \n",
      "cudatoolkit-11.1.1   | 1.20 GB   | ########## | 100% \n",
      "cudatoolkit-11.1.1   | 1.20 GB   | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... \"By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\" \n",
      "\n",
      "done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c fastchan cudatoolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed85d58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\Popin\\anaconda3\\envs\\jupyter_gpt\n",
      "\n",
      "  added / updated specs:\n",
      "    - cudatoolkit=11.1\n",
      "    - pytorch\n",
      "    - torchaudio\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    libuv-1.40.0               |       he774522_0         255 KB\n",
      "    pillow-9.0.1               |   py37hdc2b20a_0         916 KB\n",
      "    pytorch-1.11.0             |      py3.7_cpu_0       129.9 MB  pytorch\n",
      "    pytorch-mutex-1.0          |              cpu           3 KB  pytorch\n",
      "    torchaudio-0.11.0          |         py37_cpu         2.9 MB  pytorch\n",
      "    torchvision-0.12.0         |         py37_cpu         7.4 MB  pytorch\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       141.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  freetype           pkgs/main/win-64::freetype-2.10.4-hd328e21_0\n",
      "  libtiff            pkgs/main/win-64::libtiff-4.2.0-hd0e1b90_0\n",
      "  libuv              pkgs/main/win-64::libuv-1.40.0-he774522_0\n",
      "  libwebp            pkgs/main/win-64::libwebp-1.2.2-h2bbff1b_0\n",
      "  lz4-c              pkgs/main/win-64::lz4-c-1.9.3-h2bbff1b_1\n",
      "  pillow             pkgs/main/win-64::pillow-9.0.1-py37hdc2b20a_0\n",
      "  pytorch            pytorch/win-64::pytorch-1.11.0-py3.7_cpu_0\n",
      "  pytorch-mutex      pytorch/noarch::pytorch-mutex-1.0-cpu\n",
      "  tk                 pkgs/main/win-64::tk-8.6.11-h2bbff1b_0\n",
      "  torchaudio         pytorch/win-64::torchaudio-0.11.0-py37_cpu\n",
      "  torchvision        pytorch/win-64::torchvision-0.12.0-py37_cpu\n",
      "  xz                 pkgs/main/win-64::xz-5.2.5-h62dcd97_0\n",
      "  zstd               pkgs/main/win-64::zstd-1.4.9-h19a0ad4_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "libuv-1.40.0         | 255 KB    |            |   0% \n",
      "libuv-1.40.0         | 255 KB    | 6          |   6% \n",
      "libuv-1.40.0         | 255 KB    | #2         |  13% \n",
      "libuv-1.40.0         | 255 KB    | #8         |  19% \n",
      "libuv-1.40.0         | 255 KB    | ##5        |  25% \n",
      "libuv-1.40.0         | 255 KB    | ###7       |  38% \n",
      "libuv-1.40.0         | 255 KB    | #####      |  50% \n",
      "libuv-1.40.0         | 255 KB    | ######2    |  63% \n",
      "libuv-1.40.0         | 255 KB    | ########1  |  82% \n",
      "libuv-1.40.0         | 255 KB    | ########## | 100% \n",
      "libuv-1.40.0         | 255 KB    | ########## | 100% \n",
      "\n",
      "pillow-9.0.1         | 916 KB    |            |   0% \n",
      "pillow-9.0.1         | 916 KB    | 1          |   2% \n",
      "pillow-9.0.1         | 916 KB    | 3          |   3% \n",
      "pillow-9.0.1         | 916 KB    | ##         |  21% \n",
      "pillow-9.0.1         | 916 KB    | ###4       |  35% \n",
      "pillow-9.0.1         | 916 KB    | ########7  |  87% \n",
      "pillow-9.0.1         | 916 KB    | #########9 | 100% \n",
      "pillow-9.0.1         | 916 KB    | ########## | 100% \n",
      "\n",
      "torchvision-0.12.0   | 7.4 MB    |            |   0% \n",
      "torchvision-0.12.0   | 7.4 MB    |            |   0% \n",
      "torchvision-0.12.0   | 7.4 MB    |            |   0% \n",
      "torchvision-0.12.0   | 7.4 MB    |            |   1% \n",
      "torchvision-0.12.0   | 7.4 MB    |            |   1% \n",
      "torchvision-0.12.0   | 7.4 MB    | 1          |   1% \n",
      "torchvision-0.12.0   | 7.4 MB    | 1          |   2% \n",
      "torchvision-0.12.0   | 7.4 MB    | 2          |   2% \n",
      "torchvision-0.12.0   | 7.4 MB    | 2          |   3% \n",
      "torchvision-0.12.0   | 7.4 MB    | 3          |   4% \n",
      "torchvision-0.12.0   | 7.4 MB    | 4          |   5% \n",
      "torchvision-0.12.0   | 7.4 MB    | 6          |   6% \n",
      "torchvision-0.12.0   | 7.4 MB    | 7          |   8% \n",
      "torchvision-0.12.0   | 7.4 MB    | #7         |  17% \n",
      "torchvision-0.12.0   | 7.4 MB    | ##         |  20% \n",
      "torchvision-0.12.0   | 7.4 MB    | ##3        |  24% \n",
      "torchvision-0.12.0   | 7.4 MB    | ##6        |  27% \n",
      "torchvision-0.12.0   | 7.4 MB    | ###3       |  33% \n",
      "torchvision-0.12.0   | 7.4 MB    | ###9       |  39% \n",
      "torchvision-0.12.0   | 7.4 MB    | #####      |  51% \n",
      "torchvision-0.12.0   | 7.4 MB    | #####8     |  59% \n",
      "torchvision-0.12.0   | 7.4 MB    | ######5    |  65% \n",
      "torchvision-0.12.0   | 7.4 MB    | #######5   |  75% \n",
      "torchvision-0.12.0   | 7.4 MB    | ########2  |  82% \n",
      "torchvision-0.12.0   | 7.4 MB    | #########8 |  98% \n",
      "torchvision-0.12.0   | 7.4 MB    | ########## | 100% \n",
      "\n",
      "pytorch-1.11.0       | 129.9 MB  |            |   0% \n",
      "pytorch-1.11.0       | 129.9 MB  |            |   0% \n",
      "pytorch-1.11.0       | 129.9 MB  | 1          |   1% \n",
      "pytorch-1.11.0       | 129.9 MB  | 2          |   3% \n",
      "pytorch-1.11.0       | 129.9 MB  | 3          |   4% \n",
      "pytorch-1.11.0       | 129.9 MB  | 5          |   5% \n",
      "pytorch-1.11.0       | 129.9 MB  | 6          |   7% \n",
      "pytorch-1.11.0       | 129.9 MB  | 8          |   8% \n",
      "pytorch-1.11.0       | 129.9 MB  | #1         |  12% \n",
      "pytorch-1.11.0       | 129.9 MB  | #4         |  15% \n",
      "pytorch-1.11.0       | 129.9 MB  | #7         |  18% \n",
      "pytorch-1.11.0       | 129.9 MB  | ##1        |  22% \n",
      "pytorch-1.11.0       | 129.9 MB  | ##5        |  26% \n",
      "pytorch-1.11.0       | 129.9 MB  | ##9        |  30% \n",
      "pytorch-1.11.0       | 129.9 MB  | ###4       |  34% \n",
      "pytorch-1.11.0       | 129.9 MB  | ###8       |  38% \n",
      "pytorch-1.11.0       | 129.9 MB  | ####1      |  41% \n",
      "pytorch-1.11.0       | 129.9 MB  | ####5      |  46% \n",
      "pytorch-1.11.0       | 129.9 MB  | ####9      |  49% \n",
      "pytorch-1.11.0       | 129.9 MB  | #####2     |  53% \n",
      "pytorch-1.11.0       | 129.9 MB  | #####5     |  56% \n",
      "pytorch-1.11.0       | 129.9 MB  | ######4    |  65% \n",
      "pytorch-1.11.0       | 129.9 MB  | ######8    |  69% \n",
      "pytorch-1.11.0       | 129.9 MB  | #######1   |  72% \n",
      "pytorch-1.11.0       | 129.9 MB  | #######4   |  75% \n",
      "pytorch-1.11.0       | 129.9 MB  | #######8   |  78% \n",
      "pytorch-1.11.0       | 129.9 MB  | ########   |  81% \n",
      "pytorch-1.11.0       | 129.9 MB  | ########3  |  83% \n",
      "pytorch-1.11.0       | 129.9 MB  | ########5  |  85% \n",
      "pytorch-1.11.0       | 129.9 MB  | ########7  |  87% \n",
      "pytorch-1.11.0       | 129.9 MB  | ########9  |  89% \n",
      "pytorch-1.11.0       | 129.9 MB  | #########1 |  92% \n",
      "pytorch-1.11.0       | 129.9 MB  | #########4 |  94% \n",
      "pytorch-1.11.0       | 129.9 MB  | #########6 |  96% \n",
      "pytorch-1.11.0       | 129.9 MB  | #########8 |  98% \n",
      "pytorch-1.11.0       | 129.9 MB  | #########9 | 100% \n",
      "pytorch-1.11.0       | 129.9 MB  | ########## | 100% \n",
      "\n",
      "pytorch-mutex-1.0    | 3 KB      |            |   0% \n",
      "pytorch-mutex-1.0    | 3 KB      | ########## | 100% \n",
      "pytorch-mutex-1.0    | 3 KB      | ########## | 100% \n",
      "\n",
      "torchaudio-0.11.0    | 2.9 MB    |            |   0% \n",
      "torchaudio-0.11.0    | 2.9 MB    |            |   1% \n",
      "torchaudio-0.11.0    | 2.9 MB    | 1          |   1% \n",
      "torchaudio-0.11.0    | 2.9 MB    | 1          |   2% \n",
      "torchaudio-0.11.0    | 2.9 MB    | 2          |   3% \n",
      "torchaudio-0.11.0    | 2.9 MB    | 3          |   4% \n",
      "torchaudio-0.11.0    | 2.9 MB    | 4          |   5% \n",
      "torchaudio-0.11.0    | 2.9 MB    | 6          |   7% \n",
      "torchaudio-0.11.0    | 2.9 MB    | 8          |   8% \n",
      "torchaudio-0.11.0    | 2.9 MB    | #          |  10% \n",
      "torchaudio-0.11.0    | 2.9 MB    | #5         |  16% \n",
      "torchaudio-0.11.0    | 2.9 MB    | ##3        |  24% \n",
      "torchaudio-0.11.0    | 2.9 MB    | ##8        |  29% \n",
      "torchaudio-0.11.0    | 2.9 MB    | ###7       |  37% \n",
      "torchaudio-0.11.0    | 2.9 MB    | ####5      |  45% \n",
      "torchaudio-0.11.0    | 2.9 MB    | #######3   |  73% \n",
      "torchaudio-0.11.0    | 2.9 MB    | #########2 |  93% \n",
      "torchaudio-0.11.0    | 2.9 MB    | #########9 | 100% \n",
      "torchaudio-0.11.0    | 2.9 MB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "!conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf283b7",
   "metadata": {},
   "source": [
    "Now lets install HuggingFace.  It makes using popular Tranformers MUCH easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf424c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c huggingface transformers -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aba525",
   "metadata": {},
   "source": [
    "Lets import the needed packages now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31bfee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731c37a4",
   "metadata": {},
   "source": [
    "Now lets get the model.  We can either run the 1.3 billion paramater model or the 2.7 billion parameter model. Lets do the 2.7B model, which is \"EleutherAI/gpt-neo-2.7B\".  The 1.3B model is \"EleutherAI/gpt-neo-1.3B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6e795fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757381337e83443e96798f47193e71f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c9c5a32c8f48d19468dec84b1e4e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"EleutherAI/gpt-neo-2.7B\"\n",
    "model = GPTNeoForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d00f01",
   "metadata": {},
   "source": [
    "This model can be ran on a GPU, but does not have to be. The 2.7B model takes slightly less than 13 GB of Vram.  The 1.3B model takes slighly less than 7.5GB of Vram.  The model will be placed on the GPU if there is one and if there is enough Vram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5c2bc2",
   "metadata": {},
   "source": [
    "Lets install pynvml to take a look at how much VRAM we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bde9e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pynvml\n",
      "  Downloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
      "Installing collected packages: pynvml\n",
      "Successfully installed pynvml-11.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cf1002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_vram = 6\n",
    "if torch.cuda.is_available():\n",
    "    from pynvml import *\n",
    "    nvmlInit()\n",
    "    h = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(h)\n",
    "    free_vram = info.free/1048576000\n",
    "    print(\"There is a GPU with \" + str(free_vram) + \"GB of free VRAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9834d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"EleutherAI/gpt-neo-2.7B\" and free_vram>13.5:\n",
    "    use_cuda = True\n",
    "    model.to(\"cuda:0\")\n",
    "elif model_name == \"EleutherAI/gpt-neo-1.3B\" and free_vram>5:\n",
    "    use_cuda = True\n",
    "    model.to(\"cuda:0\")\n",
    "else:\n",
    "    use_cuda = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf440c",
   "metadata": {},
   "source": [
    "Now we need to load the tokenizer to prepare the input for GPT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5dd79a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5b4cbf",
   "metadata": {},
   "source": [
    "We are almost done. At this point we need to decide what prompt we need to decide what prompt we want the model to continue, as well a how long we want the generated output to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e70b4877",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17192\\548822578.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Please enter a prompt: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\jupyter_gpt\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1077\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_parent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jupyter_gpt\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1118\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1120\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1121\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "prompt = str(input(\"Please enter a prompt: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3361b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_length = int(input(\"How long should the generated output be? \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af23dde",
   "metadata": {},
   "source": [
    "We now need to tokenize the input prompt to prepare it for use with the model.  If we are using a GPU we will put it on the GPU as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed05ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "if use_cuda:\n",
    "    input_ids = input_ids.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a0ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tokens = model.generate(input_ids, do_sample=True, temperature=0.9, max_length=output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4298458",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc7f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c9c03b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_3",
   "language": "python",
   "name": "gpt_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
